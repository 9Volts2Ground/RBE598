%=========================================================================================

\section{ Discussion }

Our implementation of the ORB-SLAM algorithm onto the hexapod is able to successfully create a map of its surrounding environment. The room is shown in Figure \ref{fig:room}. Evaluating this map by visual inspection, we are able to distinguish several elements of the scene which have been constructed in the map, for instance the set of guitars along one wall of the room, the closet to the left, and the hallway to the right. Because of our lack any known-good map (due to use of real, in person measurements rather than public datasets), we are unable to make quantative statements about the accuracy of the map points that we have generated. However, it is clear that the generated map is noisy and would be difficult to use in a practical implementation, without some other information like another map of the environment known \emph{a proiri}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.04]{figures/room_pan.jpg}
    \caption{ Panoramic image of the mapped environment }
    \label{fig:room}
\end{figure}

One significant drawback of this implementation was the difficulty in obtaining and maintaining a track of the map. The camera needs to move before the first SLAM map is initialized, which means the first pose estimation from SLAM is in disagreement with the near-continuous EKF pose estimate that begins tracking immediatley. As the camera explores new areas, it was easy to lose track and drop the map again, resulting in periods where no SLAM-based pose estimation is available. The poor frame rate of the video most likely caused this, but this is a fixed hardware limitation with our implementation. When features are detected again, a new map is generated, reinitializing the pose estimate with discontinuities relative to the EKF pose. Only when loop closure occurs and maps are merged does the SLAM pose estimation snap back to the initial track. Autonomous systems typically require a smooth, continuous pose estimation approach, and ORB-SLAM would need a lot of accomidations to achieve this in a practical application.

Despite the discontinuities, the orientation estimation of SLAM appeard reasonably accurate relative to where the map initializes, especially in comparison to the estimation generated by the EKF. The EKF was prone to large drifts over time, particularly in the $\hat{z}$ direction. This is most likely due to the jittery nature of the walking gait, causing large spikes in accelerometer data that drives the EKF off truth. SLAM, on the other hand, showed responsive pose updates in response to camera motion, especially when lots of features were being tracked in the map. However, the magnitude of translation for the SLAM-generated pose estimation was off; only small translations are shown relative to the truth. A fusion of the two state estimation approaches would be benificial for practical implementation. Maintaining an EKF for each map generated by SLAM that uses the commanded twist vector, IMU data, and SLAM-based pose estimation may be a viable solution to provide continuous state estimation while taking advantage of the localization that SLAM provides. Using an external distance measurement like a range sensor may also supplement the poor scaling inherent in monocular VSLAM. 